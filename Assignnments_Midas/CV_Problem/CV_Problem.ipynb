{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHl1qk6kqwiW"
   },
   "outputs": [],
   "source": [
    "import os                        # Provides functions for interacting with the operating system                \n",
    "import numpy as np               # general-purpose array-processing package.\n",
    "import tensorflow as tf          # library for fast numerical computing created\n",
    "import pickle                    # used for serializing and de-serializing a Python object structure.\n",
    "import random                    # Random to randomise the train and validation set\n",
    "import pandas as pd              # for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # for visualization\n",
    "import zipfile                   # to work with zip files\n",
    "import collections               # containers that are used to store collections of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Extract all the files in current directory. Converted into zip because I trained model on Google Colab</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1474,
     "status": "ok",
     "timestamp": 1554850845007,
     "user": {
      "displayName": "Shivam Kushwaha",
      "photoUrl": "https://lh5.googleusercontent.com/-s9k7l_b7xl8/AAAAAAAAAAI/AAAAAAAAAZc/FtBqAc2J73U/s64/photo.jpg",
      "userId": "04484103999326154758"
     },
     "user_tz": -330
    },
    "id": "Q60J4X-PswZR",
    "outputId": "91ea95c3-f5a8-449f-ddec-02c53d7c42aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_image.pkl',\n",
       " 'train_label.pkl',\n",
       " 'hitkul(sample_submission).csv',\n",
       " 'train_image.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with zipfile.ZipFile(\"Vision_task_dataset_public-20190409T195138Z-001.zip\") as f:\n",
    "    f.extractall(\"./\")\n",
    "base_dir = \"Vision_task_dataset_public\"\n",
    "os.listdir(\"./Vision_task_dataset_public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Read the datasets from the pickle files</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1YyO97BsxP1"
   },
   "outputs": [],
   "source": [
    "train_images = pickle.load(open(os.path.join(base_dir, \"train_image.pkl\"), \"rb\"))\n",
    "test_images = pickle.load(open(os.path.join(base_dir, \"test_image.pkl\"), \"rb\"))\n",
    "train_labels = pickle.load(open(os.path.join(base_dir, \"train_label.pkl\"), \"rb\"))\n",
    "submission_df = pd.read_csv(os.path.join(base_dir, \"hitkul(sample_submission).csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Check the length of test and train dataset and length of a row in train dataset.<br>\n",
    "Getting the format of submission file</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1925,
     "status": "ok",
     "timestamp": 1554850845497,
     "user": {
      "displayName": "Shivam Kushwaha",
      "photoUrl": "https://lh5.googleusercontent.com/-s9k7l_b7xl8/AAAAAAAAAAI/AAAAAAAAAZc/FtBqAc2J73U/s64/photo.jpg",
      "userId": "04484103999326154758"
     },
     "user_tz": -330
    },
    "id": "-mZrn21Zt4EH",
    "outputId": "a3840b4c-8b13-451f-b065-26c64f94d7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000 2000 784 0 784\n",
      "[(0, 2000), (2, 2000), (3, 2000), (6, 2000)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_index  class\n",
       "0            0      2\n",
       "1            1      3\n",
       "2            2      0\n",
       "3            3      6"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_images), len(train_labels), len(test_images), len(train_images[0]), train_labels[0], len(test_images[0]))\n",
    "print(collections.Counter(train_labels).most_common())\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>To do oneHotEncoding we need the classes in sequence order so I replaced class 6 with class 1,and did oneHotEncoding<i/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCVBkg7AxzB8"
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "train_labels = np.array([1 if i==6 else i for i in train_labels])\n",
    "labels = np.zeros((len(train_labels), num_classes), dtype=np.int32)\n",
    "labels[np.arange(len(train_labels)), train_labels] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Converted the image in vector form to 2-D matrix of size 28 x 28, and displaying a random image</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3009,
     "status": "ok",
     "timestamp": 1554850846607,
     "user": {
      "displayName": "Shivam Kushwaha",
      "photoUrl": "https://lh5.googleusercontent.com/-s9k7l_b7xl8/AAAAAAAAAAI/AAAAAAAAAZc/FtBqAc2J73U/s64/photo.jpg",
      "userId": "04484103999326154758"
     },
     "user_tz": -330
    },
    "id": "uFSst-8BwD9M",
    "outputId": "80b8329d-0362-4228-83c6-18eca9c0adeb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images = np.reshape(train_images, [-1, 28, 28])\n",
    "plt.imshow(train_images[4001], cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>To perform Convolutional operation we need images in 3-D form so I converted the images in size of 28 x 28 x 1</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tq3imO6o1AwZ"
   },
   "outputs": [],
   "source": [
    "train_images = np.reshape(train_images, [-1, 28, 28, 1])\n",
    "test_images = np.reshape(test_images, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Batch Generator function generates batches of images and labels and shuffles the data if specified </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2985,
     "status": "ok",
     "timestamp": 1554850846612,
     "user": {
      "displayName": "Shivam Kushwaha",
      "photoUrl": "https://lh5.googleusercontent.com/-s9k7l_b7xl8/AAAAAAAAAAI/AAAAAAAAAZc/FtBqAc2J73U/s64/photo.jpg",
      "userId": "04484103999326154758"
     },
     "user_tz": -330
    },
    "id": "MMxnYugV5Fi8",
    "outputId": "ae7183fc-f55e-484d-bc88-0a8ce32b60fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 28, 28, 1), (128, 4))"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_generator(images, batch_size, labels=None, shuffle=True):\n",
    "    if shuffle:                                                        #shuffling the data base\n",
    "        shuff_ind = np.random.permutation(len(images))                 #np.random.permutation is useful when you need to \n",
    "                                                                       #shuffle ordered pairs, especially for classification:                \n",
    "        images = images[shuff_ind]\n",
    "        if labels is not None:\n",
    "            labels = labels[shuff_ind]\n",
    "    for i in range(len(images)//batch_size):\n",
    "        imgs = images[i*batch_size: i*batch_size+batch_size]\n",
    "        if labels is not None:\n",
    "            lbls = labels[i*batch_size: (i+1)*batch_size]\n",
    "            yield imgs, lbls\n",
    "        else:\n",
    "            yield imgs\n",
    "    return\n",
    "\n",
    "gen = batch_generator(train_images, 128, labels)\n",
    "imgs, lbls = next(gen)\n",
    "imgs.shape, lbls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Conv2d function creates a layer of Convolution operation by initialising the filters and bias, performs the convolution operation and returns the output through activation function \"relu\" <br>\n",
    "fc function creates a fully connected layer in computational graph </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWajkRF-7PHj"
   },
   "outputs": [],
   "source": [
    "def conv2d(x, out_channels, ksize, stride, padding):\n",
    "    in_shape = x.get_shape().as_list()\n",
    "    in_channels = in_shape[-1]\n",
    "    w = tf.get_variable(name=\"w\", shape=[ksize, ksize, in_channels, out_channels], dtype=tf.float32, \n",
    "                            initializer=tf.truncated_normal_initializer(mean=0., stddev=np.sqrt(1/(in_shape[1]*in_shape[2]))))\n",
    "    b = tf.get_variable(name=\"b\", shape=[out_channels], dtype=tf.float32, \n",
    "                        initializer=tf.random_uniform_initializer(minval=0., maxval=0.1))\n",
    "    return tf.nn.relu(tf.nn.conv2d(x, w, strides=[1, stride, stride, 1], padding=padding) + b)\n",
    "\n",
    "def fc(x, out, activation):\n",
    "    in_shape = x.get_shape().as_list()\n",
    "    w = tf.get_variable(name=\"w\", shape=[in_shape[-1], out], dtype=tf.float32, \n",
    "                       initializer=tf.truncated_normal_initializer(mean=0., stddev=np.sqrt(1/in_shape[-1])))\n",
    "    b = tf.get_variable(name=\"b\", shape=[out], dtype=tf.float32, \n",
    "                       initializer=tf.random_uniform_initializer(minval=0., maxval=0.1))\n",
    "    return activation(tf.matmul(x, w) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Now we define the computation graph having layers:<br>\n",
    "1-Convolution(28 x 28 x 64)<br>\n",
    "2-Max Pool(14 x 14 x 64)<br>\n",
    "3-Convolution(14 x 14 x 128)<br>\n",
    "4-Convolution(14 x 14 x 128)<br>\n",
    "5-MaxPool(7 x 7 x 128)<br>\n",
    "6-Convolution(7 x 7 x 256)<br>\n",
    "7-Flatten(7 * 7 * 256)<br>\n",
    "8-Fully connected Layer(4)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4Aigyp56H02"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inp_plh = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name=\"input_placeholder\")\n",
    "lbl_plh = tf.placeholder(dtype=tf.int32, shape=[None, num_classes], name=\"label_placeholder\")\n",
    "with tf.variable_scope(\"layer1\"):\n",
    "    conv = conv2d(inp_plh, 64, 3, 1, \"SAME\")\n",
    "mp = tf.nn.max_pool(conv, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "with tf.variable_scope(\"layer2\"):\n",
    "    conv = conv2d(mp, 128, 3, 1, \"SAME\")\n",
    "with tf.variable_scope(\"layer3\"):\n",
    "    conv = conv2d(conv, 128, 3, 1, \"SAME\")\n",
    "mp = tf.nn.max_pool(conv, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "with tf.variable_scope(\"layer4\"):\n",
    "    conv = conv2d(mp, 256, 3, 1, \"SAME\")\n",
    "flattened = tf.reshape(conv, [-1, 7*7*256])\n",
    "with tf.variable_scope(\"layer5\"):\n",
    "    logits = fc(flattened, num_classes, lambda x: x)\n",
    "pred_prob = tf.nn.softmax(logits)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=lbl_plh))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred_prob, axis=1), tf.argmax(lbl_plh, axis=1)), dtype=tf.float32))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Below codes are used to train the data and calculating average accuracy and loss after each epoch. <br>\n",
    "then we predict on the test data.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2554
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78514,
     "status": "ok",
     "timestamp": 1554850922182,
     "user": {
      "displayName": "Shivam Kushwaha",
      "photoUrl": "https://lh5.googleusercontent.com/-s9k7l_b7xl8/AAAAAAAAAAI/AAAAAAAAAZc/FtBqAc2J73U/s64/photo.jpg",
      "userId": "04484103999326154758"
     },
     "user_tz": -330
    },
    "id": "WFqZ02czDWVZ",
    "outputId": "284619ad-e84a-4a9d-9264-f58c70343494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed\n",
      "Average Loss:  42.09049\n",
      "Average Accuracy:  0.5302419\n",
      "Epoch 2 completed\n",
      "Average Loss:  0.8670434\n",
      "Average Accuracy:  0.7581905\n",
      "Epoch 3 completed\n",
      "Average Loss:  0.5020708\n",
      "Average Accuracy:  0.81602824\n",
      "Epoch 4 completed\n",
      "Average Loss:  0.41239586\n",
      "Average Accuracy:  0.8453881\n",
      "Epoch 5 completed\n",
      "Average Loss:  0.34510937\n",
      "Average Accuracy:  0.8671875\n",
      "Epoch 6 completed\n",
      "Average Loss:  0.2988869\n",
      "Average Accuracy:  0.88671875\n",
      "Epoch 7 completed\n",
      "Average Loss:  0.271472\n",
      "Average Accuracy:  0.8985635\n",
      "Epoch 8 completed\n",
      "Average Loss:  0.2442009\n",
      "Average Accuracy:  0.9073841\n",
      "Epoch 9 completed\n",
      "Average Loss:  0.20878759\n",
      "Average Accuracy:  0.92552924\n",
      "Epoch 10 completed\n",
      "Average Loss:  0.18208215\n",
      "Average Accuracy:  0.93472785\n",
      "Epoch 11 completed\n",
      "Average Loss:  0.15186056\n",
      "Average Accuracy:  0.94821066\n",
      "Epoch 12 completed\n",
      "Average Loss:  0.12761654\n",
      "Average Accuracy:  0.9610635\n",
      "Epoch 13 completed\n",
      "Average Loss:  0.1112223\n",
      "Average Accuracy:  0.96522176\n",
      "Epoch 14 completed\n",
      "Average Loss:  0.0894066\n",
      "Average Accuracy:  0.97442037\n",
      "Epoch 15 completed\n",
      "Average Loss:  0.07711342\n",
      "Average Accuracy:  0.9784526\n",
      "Epoch 16 completed\n",
      "Average Loss:  0.076058544\n",
      "Average Accuracy:  0.9756805\n",
      "Epoch 17 completed\n",
      "Average Loss:  0.055309556\n",
      "Average Accuracy:  0.98714715\n",
      "Epoch 18 completed\n",
      "Average Loss:  0.042755708\n",
      "Average Accuracy:  0.9925655\n",
      "Epoch 19 completed\n",
      "Average Loss:  0.034907207\n",
      "Average Accuracy:  0.99432963\n",
      "Epoch 20 completed\n",
      "Average Loss:  0.028104244\n",
      "Average Accuracy:  0.99747986\n",
      "Epoch 21 completed\n",
      "Average Loss:  0.022445364\n",
      "Average Accuracy:  0.9986139\n",
      "Epoch 22 completed\n",
      "Average Loss:  0.016164558\n",
      "Average Accuracy:  0.999496\n",
      "Epoch 23 completed\n",
      "Average Loss:  0.012588974\n",
      "Average Accuracy:  1.0\n",
      "Epoch 24 completed\n",
      "Average Loss:  0.010431136\n",
      "Average Accuracy:  1.0\n",
      "Epoch 25 completed\n",
      "Average Loss:  0.0084797265\n",
      "Average Accuracy:  1.0\n",
      "Epoch 26 completed\n",
      "Average Loss:  0.0073286914\n",
      "Average Accuracy:  1.0\n",
      "Epoch 27 completed\n",
      "Average Loss:  0.006272136\n",
      "Average Accuracy:  1.0\n",
      "Epoch 28 completed\n",
      "Average Loss:  0.0056410683\n",
      "Average Accuracy:  1.0\n",
      "Epoch 29 completed\n",
      "Average Loss:  0.0050450205\n",
      "Average Accuracy:  1.0\n",
      "Epoch 30 completed\n",
      "Average Loss:  0.004598683\n",
      "Average Accuracy:  1.0\n",
      "Epoch 31 completed\n",
      "Average Loss:  0.003930122\n",
      "Average Accuracy:  1.0\n",
      "Epoch 32 completed\n",
      "Average Loss:  0.00364264\n",
      "Average Accuracy:  1.0\n",
      "Epoch 33 completed\n",
      "Average Loss:  0.0033825214\n",
      "Average Accuracy:  1.0\n",
      "Epoch 34 completed\n",
      "Average Loss:  0.003129502\n",
      "Average Accuracy:  1.0\n",
      "Epoch 35 completed\n",
      "Average Loss:  0.00273758\n",
      "Average Accuracy:  1.0\n",
      "Epoch 36 completed\n",
      "Average Loss:  0.002614181\n",
      "Average Accuracy:  1.0\n",
      "Epoch 37 completed\n",
      "Average Loss:  0.002422125\n",
      "Average Accuracy:  1.0\n",
      "Epoch 38 completed\n",
      "Average Loss:  0.002165147\n",
      "Average Accuracy:  1.0\n",
      "Epoch 39 completed\n",
      "Average Loss:  0.0020616455\n",
      "Average Accuracy:  1.0\n",
      "Epoch 40 completed\n",
      "Average Loss:  0.0019314414\n",
      "Average Accuracy:  1.0\n",
      "Epoch 41 completed\n",
      "Average Loss:  0.0017804733\n",
      "Average Accuracy:  1.0\n",
      "Epoch 42 completed\n",
      "Average Loss:  0.0016345966\n",
      "Average Accuracy:  1.0\n",
      "Epoch 43 completed\n",
      "Average Loss:  0.0015345928\n",
      "Average Accuracy:  1.0\n",
      "Epoch 44 completed\n",
      "Average Loss:  0.0014651959\n",
      "Average Accuracy:  1.0\n",
      "Epoch 45 completed\n",
      "Average Loss:  0.0013744219\n",
      "Average Accuracy:  1.0\n",
      "Epoch 46 completed\n",
      "Average Loss:  0.0012846199\n",
      "Average Accuracy:  1.0\n",
      "Epoch 47 completed\n",
      "Average Loss:  0.0012091569\n",
      "Average Accuracy:  1.0\n",
      "Epoch 48 completed\n",
      "Average Loss:  0.0011452041\n",
      "Average Accuracy:  1.0\n",
      "Epoch 49 completed\n",
      "Average Loss:  0.0010776971\n",
      "Average Accuracy:  1.0\n",
      "Epoch 50 completed\n",
      "Average Loss:  0.0010183862\n",
      "Average Accuracy:  1.0\n",
      "Predicting\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(50):\n",
    "        acc_list = []\n",
    "        loss_list = []\n",
    "        gen = batch_generator(train_images, 256, labels)\n",
    "        for imgs, lbls in gen:\n",
    "            _, loss_val, acc_val = sess.run([optimizer, loss, accuracy], feed_dict={inp_plh: imgs, lbl_plh: lbls})\n",
    "            acc_list.append(acc_val)\n",
    "            loss_list.append(loss_val)\n",
    "        print(\"Epoch %d completed\"%(epoch+1))\n",
    "        print(\"Average Loss: \", np.mean(loss_list))\n",
    "        print(\"Average Accuracy: \", np.mean(acc_list))\n",
    "    print(\"Predicting\")\n",
    "    test_labels = []\n",
    "    gen = batch_generator(test_images, 100, shuffle=False)\n",
    "    for imgs in gen:\n",
    "        pred_val = sess.run(pred_prob, feed_dict={inp_plh: imgs})\n",
    "        pred_val = np.argmax(pred_val, axis=1)\n",
    "        test_labels.extend(pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>During oneHotEncoding we have replaced 6 with 1 so here we are replacing 1 with 6 and generating submisson.csv file after predicting on the test set.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1168,
     "status": "ok",
     "timestamp": 1554851021691,
     "user": {
      "displayName": "Shivam Kushwaha",
      "photoUrl": "https://lh5.googleusercontent.com/-s9k7l_b7xl8/AAAAAAAAAAI/AAAAAAAAAZc/FtBqAc2J73U/s64/photo.jpg",
      "userId": "04484103999326154758"
     },
     "user_tz": -330
    },
    "id": "DKUtpD7DUPjx",
    "outputId": "91c99d85-c6d4-41f3-d4b4-6fe001c06716"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_index  class\n",
       "0             0      0\n",
       "1             1      0\n",
       "2             2      0\n",
       "3             3      0\n",
       "4             4      0\n",
       "5             5      0\n",
       "6             6      0\n",
       "7             7      0\n",
       "8             8      0\n",
       "9             9      0\n",
       "10           10      0\n",
       "11           11      0\n",
       "12           12      0\n",
       "13           13      0\n",
       "14           14      0\n",
       "15           15      0\n",
       "16           16      0\n",
       "17           17      0\n",
       "18           18      0\n",
       "19           19      0\n",
       "20           20      0\n",
       "21           21      0\n",
       "22           22      0\n",
       "23           23      6\n",
       "24           24      0\n",
       "25           25      0\n",
       "26           26      0\n",
       "27           27      0\n",
       "28           28      0\n",
       "29           29      0\n",
       "30           30      0\n",
       "31           31      0\n",
       "32           32      0\n",
       "33           33      0\n",
       "34           34      3\n",
       "35           35      0\n",
       "36           36      0\n",
       "37           37      2\n",
       "38           38      0\n",
       "39           39      0\n",
       "40           40      6\n",
       "41           41      0\n",
       "42           42      0\n",
       "43           43      0\n",
       "44           44      0\n",
       "45           45      0\n",
       "46           46      0\n",
       "47           47      6\n",
       "48           48      0\n",
       "49           49      0"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = [6 if i==1 else i for i in test_labels]\n",
    "submission = pd.DataFrame()\n",
    "submission[\"image_index\"] = list(range(len(test_images)))\n",
    "submission[\"class\"] = test_labels\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head(50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sahu Bhai.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
