{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of indic2019 - east 1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahushivam/MachineLearning/blob/master/Colab/Copy_of_indic2019_east_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18TyZ2gdj1M0",
        "colab_type": "text"
      },
      "source": [
        "Import statement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHEqF-yWed3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==1.13.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOHQBK7L2xGL",
        "colab_type": "code",
        "outputId": "df8026dc-fb0f-48b1-9c14-88183fdd7158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import tarfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import IPython.display as display\n",
        "import tensorboardcolab as tbc\n",
        "tbc = tbc.TensorBoardColab()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://9901ab09.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEnpRvIIj8Bf",
        "colab_type": "text"
      },
      "source": [
        "Write in tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YODBqo73ST5",
        "colab_type": "code",
        "outputId": "a6b23394-72e4-4cae-f7bb-a0bcf3b3eab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "writer = tbc.get_writer()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 08:12:50.097071 140187324671872 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfs1-_8BkBCH",
        "colab_type": "text"
      },
      "source": [
        "Defining the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY0PLFYt7kY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "nb_boxes=1\n",
        "grid_w=2\n",
        "grid_h=2\n",
        "cell_w=14\n",
        "cell_h=14\n",
        "img_w=28\n",
        "img_h=28\n",
        "img_channels = 1\n",
        "input_shape = (None, img_w, img_h, img_channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaAb8BnjkGAX",
        "colab_type": "text"
      },
      "source": [
        "Extract function takes data record and return images and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALfgwMiBwrcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_fn(data_record):\n",
        "    features = {\n",
        "      'image': tf.FixedLenFeature([], tf.string),\n",
        "      'label': tf.FixedLenFeature([5], tf.float32)\n",
        "    }\n",
        "    data = tf.parse_single_example(data_record, features)\n",
        "    img1 = tf.decode_raw(data['image'], tf.float32)\n",
        "    img1 = tf.reshape(img1, (img_w, img_h, img_channels)) #reshape to 28 x 28 x 1\n",
        "    img1 = tf.image.per_image_standardization(img1) #Standardizing\n",
        "    return img1, data['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5olAO8qcwyk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files_pattern = '/gdrive/My Drive/indic2019/TFRecords/*.tfrecord' #file pattern for tf record\n",
        "test_pattern = '/gdrive/My Drive/indic2019/Test/*.tfrecord' #file pattern for testing it on the test pattern\n",
        "test_image = '/gdrive/My Drive/indic2019/images/10_10.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_dayQslkr_S",
        "colab_type": "text"
      },
      "source": [
        "<h3> Input function</h3>\n",
        "  <ul>\n",
        "    <li>Input parameters are files pattern(for taking data from the input), batch_size and mode(predict,eval and train)</li>\n",
        "  <li>Returns features and label in case of eval and train and features in case of predict</li>\n",
        "    </ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRK9pLE237aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(files_pattern,batch_size, mode):\n",
        "  print(batch_size)\n",
        "  files = tf.data.Dataset.list_files(files_pattern, shuffle=True)\n",
        "  dataset = files.apply(tf.contrib.data.parallel_interleave( lambda filename: tf.data.TFRecordDataset(filename), cycle_length=1)) \n",
        "  #T parallel_interleave-HIS FUNCTION IS DEPRECATED. (not exactly know)\n",
        "    \n",
        "  #three variables for three mode\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  is_eval = (mode == tf.estimator.ModeKeys.EVAL)\n",
        "  is_predict = (mode== tf.estimator.ModeKeys.PREDICT)\n",
        "  \n",
        "  buffer_size = batch_size * 2 + 1\n",
        "  dataset = dataset.shuffle(buffer_size=buffer_size)\n",
        "\n",
        "  # Transformation\n",
        "  dataset = dataset.map(extract_fn)\n",
        "  \n",
        "  if is_training or is_predict:\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(2 * batch_size)\n",
        "    \n",
        "  if is_eval:\n",
        "    buffer_size = batch_size * 10\n",
        "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(10 * batch_size)\n",
        "\n",
        "  image, label = dataset.make_one_shot_iterator().get_next()\n",
        "  features = {'images': image}\n",
        "  \n",
        "  if is_training or is_eval:\n",
        "    return features, label\n",
        "  \n",
        "  if is_predict:\n",
        "    return features "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2VKVF0MvNR0",
        "colab_type": "text"
      },
      "source": [
        "<h3> Custom loss </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkD41DymzZxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def custom_loss(labels,logits):\n",
        "  \n",
        "  print(logits)\n",
        "  \n",
        "  true_confidence = labels[:,0]\n",
        "  true_x=labels[:,1]\n",
        "  true_y=labels[:,2]\n",
        "  true_w=labels[:,3]\n",
        "  true_h=labels[:,4]\n",
        "\n",
        "  predict_confidence=logits[:,0]\n",
        "  predict_x=logits[:,1]\n",
        "  predict_y=logits[:,2]\n",
        "  predict_w=logits[:,3]\n",
        "  predict_h=logits[:,4]\t\n",
        "\n",
        "  xy_loss= K.square(true_x-predict_x) + K.square(true_y-predict_y)\n",
        "  wh_loss= K.square(K.sqrt(true_w)-K.sqrt(predict_w))+ K.square(K.sqrt(true_h)-K.sqrt(predict_h))\n",
        "\n",
        "  con_loss=K.square(true_confidence-predict_confidence)\n",
        "\n",
        "  loss= xy_loss + wh_loss + con_loss\n",
        "  return tf.math.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL9FqQhNLh4A",
        "colab_type": "text"
      },
      "source": [
        "**Loss function as given in east implementation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DebveU5_L2_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_classification(true_class, pred_class,\n",
        "                     training_mask=1):\n",
        "    eps = 1e-5\n",
        "    intersection = tf.reduce_sum(true_class * pred_class * training_mask)\n",
        "    union = tf.reduce_sum(true_class * training_mask) + tf.reduce_sum(pred_class * training_mask) + eps\n",
        "    loss = 1. - (2 * intersection / union)\n",
        "    tf.summary.scalar('classification_loss', loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Md7eqXCLR_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels,logits,training_mask):\n",
        "\n",
        "    true_class=labels[:,0]\n",
        "    classification_loss = class_classification(true_class, pred_class, training_mask)\n",
        "    # scale classification loss to match the iou loss part\n",
        "    classification_loss *= 0.01\n",
        "\n",
        "    # d1 -> top, d2->right, d3->bottom, d4->left\n",
        "    d1_gt, d2_gt, d3_gt, d4_gt, theta_gt = tf.split(value=true_bound, num_or_size_splits=5, axis=3)\n",
        "    d1_pred, d2_pred, d3_pred, d4_pred, theta_pred = tf.split(value=pred_bound, num_or_size_splits=5, axis=3)\n",
        "    area_gt = (d1_gt + d3_gt) * (d2_gt + d4_gt)\n",
        "    area_pred = (d1_pred + d3_pred) * (d2_pred + d4_pred)\n",
        "    w_union = tf.minimum(d2_gt, d2_pred) + tf.minimum(d4_gt, d4_pred)\n",
        "    h_union = tf.minimum(d1_gt, d1_pred) + tf.minimum(d3_gt, d3_pred)\n",
        "    area_intersect = w_union * h_union\n",
        "    area_union = area_gt + area_pred - area_intersect\n",
        "    L_AABB = -tf.log((area_intersect + 1.0)/(area_union + 1.0))\n",
        "    L_theta = 1 - tf.cos(theta_pred - theta_gt)\n",
        "    tf.summary.scalar('geometry_AABB', tf.reduce_mean(L_AABB * true_class * training_mask))\n",
        "    tf.summary.scalar('geometry_theta', tf.reduce_mean(L_theta * true_class * training_mask))\n",
        "    L_g = L_AABB + 20 * L_theta\n",
        "\n",
        "    return tf.reduce_mean(L_g * true_class * training_mask) + classification_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL28NPPyvm26",
        "colab_type": "text"
      },
      "source": [
        "<h3>Bounding Box</h3>\n",
        "Returns coordinates of bounding box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVmc-_5tMY60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shape of y : conf x y w h\n",
        "\n",
        "def convert_to_coord(y):\n",
        "  coord= []\n",
        "  bb_box_width = y[:,3] * img_w\n",
        "  bb_box_height = y[:,4] * img_h\n",
        "  center_x = y[:,1] * img_w\n",
        "  center_y = y[:,2] * img_h\n",
        "  coord.append((center_x - (bb_box_width / 2)))\n",
        "  coord.append((center_y - (bb_box_height / 2)))\n",
        "  coord.append((center_x + (bb_box_width / 2)))\n",
        "  coord.append((center_y + (bb_box_height / 2)))\n",
        "  \n",
        "  return coord\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPx1YpCWwG_g",
        "colab_type": "text"
      },
      "source": [
        "<h3>IOU Loss</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkvKonJyNXaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def iou_loss(labels,logits):\n",
        "  #Convert the arrays to absolute coordinates\n",
        "  coord_labels = convert_to_coord(labels)\n",
        "  coord_logits = convert_to_coord(logits)\n",
        "  \n",
        "  # Calculate the (y1, x1, y2, x2) coordinates of the intersection of box1 and box2.Calculate its Area.\n",
        "  xi1 = tf.math.maximum((coord_labels[0]), (coord_logits[0]))\n",
        "  yi1 = tf.math.maximum((coord_labels[1]), (coord_logits[1]))\n",
        "  xi2 = tf.math.minimum((coord_labels[2]), (coord_logits[2]))\n",
        "  yi2 = tf.math.minimum((coord_labels[3]), (coord_logits[3]))\n",
        "  inter_area = tf.math.maximum((yi2-yi1), 0) * tf.math.maximum((xi2-xi1), 0)\n",
        "  \n",
        "  # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "  box1_area = (coord_labels[3] - coord_labels[1])*(coord_labels[2]- coord_labels[0])\n",
        "  box2_area = (coord_logits[3] - coord_logits[1])*(coord_logits[2]- coord_logits[0])\n",
        "  union_area = (box1_area + box2_area) - inter_area\n",
        "  # compute the IoU\n",
        "  \n",
        "  iou =inter_area / union_area\n",
        "\n",
        "  return iou\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_-8L9oYmr54",
        "colab_type": "text"
      },
      "source": [
        "<h3>Feature Columns</h3>\n",
        "The feature columns is an intermediaries between raw data and Estimators.<br/>\n",
        "Feature columns bridge raw data with the data your model needs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T-N-ccCdy5AU",
        "colab": {}
      },
      "source": [
        "def get_feature_columns():\n",
        "  feature_columns = {'images': tf.feature_column.numeric_column('images', (28, 28, 1))}\n",
        "  return feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsgn5nVrIcyD",
        "colab_type": "text"
      },
      "source": [
        "**Unpool used in Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJRngaBIbYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpool(inputs):\n",
        "    return tf.image.resize_bilinear(inputs, size=[tf.shape(inputs)[1]*2,  tf.shape(inputs)[2]*2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32tEiXzZu9jq",
        "colab_type": "text"
      },
      "source": [
        "<h3>Base Model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOSsq5V7RoiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def base_model(input,batch_size, input_shape):\n",
        "  \n",
        "  #print(input.shape)\n",
        "  #print(batch_size)\n",
        "  \n",
        "  #tf.name_scope()\n",
        "  #Conv Layer - 1\n",
        "  #Input is 28*28 and with kernal size= 5*5 and 16 filters it is reduced to 28-5+1= 24*24\n",
        "  with tf.name_scope('Conv_s_4') as scope:\n",
        "    x_s_4 = tf.keras.layers.Conv2D(16,(5,5), input_shape = input_shape , name=\"Conv_4\",\n",
        "                             use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                             bias_initializer='zeros')(input)\n",
        "    x_s_4 = tf.keras.layers.BatchNormalization()(x_s_4)\n",
        "    x_s_4 = tf.keras.layers.ReLU()(x_s_4)\n",
        "    unpooled_output_4=x_s_4\n",
        "    x_s_4= tf.keras.layers.MaxPooling2D()(x_s_4) \n",
        "    \n",
        "    output_4 = x_s_4\n",
        "    print(\"output_4\")\n",
        "    print(output_4)\n",
        "\n",
        "  with tf.name_scope('Conv_s_3') as scope:\n",
        "    x_s_3 = tf.keras.layers.Conv2D(16,(5,5), name=\"Conv_3\",\n",
        "                             use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                             bias_initializer='zeros')(x_s_4)\n",
        "    x_s_3 = tf.keras.layers.BatchNormalization()(x_s_3)\n",
        "    x_s_3 = tf.keras.layers.ReLU()(x_s_3)\n",
        "    unpooled_output_3=x_s_3\n",
        "    #x= tf.keras.layers.MaxPooling2D()(x)\n",
        "  \n",
        "    output_3 = x_s_3\n",
        "  print(\"output_3\")\n",
        "  print(output_3)\n",
        "  \n",
        "  with tf.name_scope('Conv_s_2') as scope:\n",
        "    x_s_2 = tf.keras.layers.Conv2D(16,(5,5), name=\"Conv_2\",\n",
        "                             use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                             bias_initializer='zeros')(x_s_3)\n",
        "    x_s_2 = tf.keras.layers.BatchNormalization()(x_s_2)\n",
        "    x_s_2 = tf.keras.layers.ReLU()(x_s_2)\n",
        "    unpooled_output_2=x_s_2\n",
        "    #x= tf.keras.layers.MaxPooling2D()(x)\n",
        "    \n",
        "  output_2 = x_s_2\n",
        "  print(\"output_2\")\n",
        "  print(output_2)\n",
        "  \n",
        "  with tf.name_scope('Conv_s_1') as scope:\n",
        "    x_s_1 = tf.keras.layers.Conv2D(16,(1,1), name=\"Conv_1\",\n",
        "                             use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                             bias_initializer='zeros')(x_s_2)\n",
        "    x_s_1 = tf.keras.layers.BatchNormalization()(x_s_1)\n",
        "    x_s_1 = tf.keras.layers.ReLU()(x_s_1)\n",
        "  \n",
        "  unpooled_output_1=x_s_1\n",
        "  print('Printing Output 1')\n",
        "  print(unpooled_output_1)\n",
        "  \n",
        "  #first stack layer ends we have all the unpooled layer of conv2D(4,3,2,1) \n",
        "  #named unpooled_output_4,unpooled_output_3,unpooled_output_2,unpooled_output_1\n",
        "  with tf.name_scope('feature_merging_branch') as scope:\n",
        "    output_1_resized = tf.image.resize_bilinear(unpooled_output_1, size=[4, 4])\n",
        "    print('outut_1_resized bilinear')\n",
        "    print(output_1_resized)\n",
        "\n",
        "    y = tf.keras.layers.concatenate([output_2,output_1_resized], axis=3)\n",
        "    print('Concatenation of output_2 and output_1_resized')\n",
        "    print(y)\n",
        "    with tf.name_scope('Conv_5_0') as scope:\n",
        "      y5 = tf.keras.layers.Conv2D(16,(1,1), name=\"Conv_5_0\",\n",
        "                               use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                               bias_initializer='zeros')(y)\n",
        "      y5 = tf.keras.layers.BatchNormalization()(y5)\n",
        "      y5 = tf.keras.layers.ReLU()(y5)\n",
        "    \n",
        "    with tf.name_scope('Conv_5_1') as scope:\n",
        "      y5_1 = tf.keras.layers.Conv2D(16,(3,3), name=\"Conv_5_1\",\n",
        "                               use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                               bias_initializer='zeros')(y5)\n",
        "      y5_1 = tf.keras.layers.BatchNormalization()(y5_1)\n",
        "      y5_1 = tf.keras.layers.ReLU()(y5_1)\n",
        "      print(y5_1)\n",
        "      \n",
        "      output_3_resized = tf.image.resize_bilinear(unpooled_output_3, size=[2, 2])\n",
        "      print(\"output_3_resized\")\n",
        "      print(output_3_resized)\n",
        "    #now we have to built another conv2D which will concatenate y5_1 and unpooled_output_3\n",
        "    \n",
        "    with tf.name_scope('Conv_6_0') as scope:\n",
        "      y6 = tf.keras.layers.concatenate([y5_1,output_3_resized], axis=3)\n",
        "      y6 = tf.keras.layers.Conv2D(16,(1,1), name=\"Conv_6_0\",\n",
        "                               use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                               bias_initializer='zeros')(y6)\n",
        "      y6 = tf.keras.layers.BatchNormalization()(y6)\n",
        "      y6 = tf.keras.layers.ReLU()(y6)\n",
        "    \n",
        "    #instead of 1*1 kernal size we needed 3*3 kernal size but as it making the dimension negative I have used 1*1 kernal size\n",
        "    with tf.name_scope('Conv_6_1') as scope:\n",
        "      y6_1 = tf.keras.layers.Conv2D(16,(1,1), name=\"Conv_6_1\",\n",
        "                               use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                               bias_initializer='zeros')(y6)\n",
        "      y6_1 = tf.keras.layers.BatchNormalization()(y6_1)\n",
        "      y6_1 = tf.keras.layers.ReLU()(y6_1)\n",
        "      print(y6_1)\n",
        "      \n",
        "    #now we have to built another conv2D which will concatenate y6_1(size is 2*2*16) and unpooled_output_4(size is 12*12*16)\n",
        "    with tf.name_scope('Conv_7_0') as scope:\n",
        "      output_4_resized = tf.image.resize_bilinear(unpooled_output_4, size=[2, 2])\n",
        "      y7 = tf.keras.layers.concatenate([y6_1,output_4_resized], axis=3)\n",
        "      y7 = tf.keras.layers.Conv2D(16,(1,1), name=\"Conv_7_0\",\n",
        "                               use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                               bias_initializer='zeros')(y7)\n",
        "      y7 = tf.keras.layers.BatchNormalization()(y7)\n",
        "      y7 = tf.keras.layers.ReLU()(y7)\n",
        "    #instead of 1*1 kernal size we needed 3*3 kernal size but as it making the dimension negative I have used 1*1 kernal size\n",
        "    with tf.name_scope('Conv_7_1') as scope:\n",
        "      y7_1 = tf.keras.layers.Conv2D(16,(1,1), name=\"Conv_7_1\",\n",
        "                               use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                               bias_initializer='zeros')(y7)\n",
        "      y7_1 = tf.keras.layers.BatchNormalization()(y7_1)\n",
        "      y7_1 = tf.keras.layers.ReLU()(y7_1)\n",
        "      print(y7_1)\n",
        "      \n",
        "    y = tf.keras.layers.Conv2D(16,(1,1), name=\"Conv_8\",\n",
        "                               use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                               bias_initializer='zeros')(y7_1)\n",
        "    y = tf.keras.layers.BatchNormalization()(y)\n",
        "    y = tf.keras.layers.ReLU()(y)\n",
        "    \n",
        "    \n",
        "  \n",
        "  #print(x)\n",
        "  \n",
        "  #Flatten it out\n",
        "  y = tf.keras.layers.Flatten(name=\"Flatten_1\")(y)\n",
        "  #print(\"After flatten\")\n",
        "  #print(x)\n",
        "  \n",
        "  #Dense layer\n",
        "  y = tf.keras.layers.Dense(16, activation=\"sigmoid\", name=\"Dense1\")(y)\n",
        "  #print(x)\n",
        "  y = tf.keras.layers.Dense(5, activation='sigmoid')(y)\n",
        "  #print(x)\n",
        "  # x = tf.keras.layers.Reshape((2*2, (1*5)), name= 'model_final_reshape')(x)\n",
        "  \n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoUlQadYdb14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62R63_cNvgL1",
        "colab_type": "text"
      },
      "source": [
        "<h3>Model Function</h3>\n",
        "<ul>\n",
        "  <li>input is features, labels, mode and parameters</li>\n",
        "</ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQn0Lq1O2QZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(features, labels, mode):\n",
        "                                                                                                \n",
        "  feature_columns = list(get_feature_columns().values())\n",
        "  images = tf.feature_column.input_layer(features=features, feature_columns=feature_columns)\n",
        "  images = tf.reshape(images, shape=(-1, 28, 28, 1),name='my_reshape')\n",
        "\n",
        "\n",
        "  # Calculate logits through CNN                                                                                                            \n",
        "  logits = base_model(images,batch_size, input_shape)\n",
        "\n",
        "  # Create the input layers from the features \n",
        "  if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n",
        "    global_step = tf.train.get_or_create_global_step()#create default graph\n",
        "    loss=custom_loss(labels,logits) #loss \n",
        "    iou = iou_loss(labels,logits) \n",
        "    tf.summary.scalar('IOU', tf.math.reduce_mean(iou))\n",
        "    tf.summary.scalar('Loss', loss)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    predictions = {'coordinates': logits}\n",
        "    export_outputs = {'coordinates': tf.estimator.export.PredictOutput(predictions)}\n",
        "    return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.EVAL:\n",
        "    iou = iou_loss(labels,logits)\n",
        "    eval_metric_ops = {'iou_eval': tf.metrics.mean(iou)}\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001,beta1=0.9,beta2=0.999,epsilon=1e-08,use_locking=False,name='Adam')\n",
        "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM_4JOxFzXfJ",
        "colab_type": "text"
      },
      "source": [
        "Preprocess is used in serving_input_fn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0DU9h4vNbao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(filename):\n",
        "    # decode the image file starting from the filename\n",
        "    image_contents = tf.read_file(filename)\n",
        "    img_decoded = tf.image.decode_jpeg(image_contents, channels=img_channels)\n",
        "    image = tf.image.convert_image_dtype(img_decoded, dtype=tf.float32) # 0-1\n",
        "    img_expanded = tf.expand_dims(image, 0)\n",
        "    img_resize = tf.image.resize_bilinear(img_expanded,(img_w, img_h))\n",
        "    img_squeezed = tf.squeeze(img_resize,0)\n",
        "    img_standardized = tf.image.per_image_standardization(img_squeezed)\n",
        "    img_expanded = tf.expand_dims(img_standardized, 0)\n",
        "    image= tf.reshape(img_expanded, (-1, img_w, img_h, img_channels), name='serve_reshape')\n",
        "    return image\n",
        "\n",
        "def serving_input_fn():\n",
        "  #()code to read the image from url\n",
        "  receiver_tensor = {'image_bytes': tf.placeholder(dtype=tf.string, shape=[1])}\n",
        "  image = (receiver_tensor['image_bytes'])[0]\n",
        "  img_expanded = preprocess(image)\n",
        "  # make the outer dimension unknown (and not 1)\n",
        "  image = tf.placeholder_with_default(img_expanded, shape=[None, img_w, img_h, img_channels])\n",
        "  features = {'images': image}\n",
        "  return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCRJa3dH3yud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_config = tf.estimator.RunConfig(model_dir='./Graph6', save_summary_steps=10, save_checkpoints_secs = 300, keep_checkpoint_max = 5)\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
        "\n",
        "# There is another Exporter named FinalExporter which exports the serving graph and checkpoints at the end.\n",
        "\n",
        "exporter = tf.estimator.LatestExporter(\n",
        "  name='Serve',\n",
        "  serving_input_receiver_fn=serving_input_fn,\n",
        "  assets_extra=None,\n",
        "  as_text=False,\n",
        "  exports_to_keep=5)\n",
        "\n",
        "train_spec = tf.estimator.TrainSpec(input_fn= lambda:input_fn(files_pattern, batch_size, mode=tf.estimator.ModeKeys.TRAIN))\n",
        "\n",
        "eval_spec = tf.estimator.EvalSpec(lambda: input_fn(files_pattern,  batch_size , mode=tf.estimator.ModeKeys.EVAL), exporters=exporter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjod791FBBpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.add_graph(tf.get_default_graph())\n",
        "writer.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMHahF8sOT_B",
        "colab_type": "code",
        "outputId": "345c914e-dc16-4e0d-df2e-c924ac5f3606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "writer.add_graph(tf.get_default_graph())\n",
        "writer.flush()\n",
        "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0715 08:13:17.537418 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0715 08:13:19.999943 140187324671872 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0715 08:13:20.001620 140187324671872 deprecation.py:323] From <ipython-input-6-270cfefeea91>:4: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0715 08:13:20.002711 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0715 08:13:20.082668 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0715 08:13:20.100236 140187324671872 deprecation.py:323] From <ipython-input-6-270cfefeea91>:28: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0715 08:13:20.140178 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0715 08:13:20.141545 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2115: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0715 08:13:20.142942 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0715 08:13:20.159234 140187324671872 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "output_4\n",
            "Tensor(\"Conv_s_4/max_pooling2d/MaxPool:0\", shape=(?, 12, 12, 16), dtype=float32)\n",
            "output_3\n",
            "Tensor(\"Conv_s_3/re_lu_1/Relu:0\", shape=(?, 8, 8, 16), dtype=float32)\n",
            "output_2\n",
            "Tensor(\"Conv_s_2/re_lu_2/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Printing Output 1\n",
            "Tensor(\"Conv_s_1/re_lu_3/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "outut_1_resized bilinear\n",
            "Tensor(\"feature_merging_branch/ResizeBilinear:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Concatenation of output_2 and output_1_resized\n",
            "Tensor(\"feature_merging_branch/concatenate/concat:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/re_lu_5/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "output_3_resized\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/ResizeBilinear:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_6_1/re_lu_7/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_7_1/re_lu_9/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"dense/Sigmoid:0\", shape=(?, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0715 08:13:21.543404 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "output_4\n",
            "Tensor(\"Conv_s_4/max_pooling2d/MaxPool:0\", shape=(?, 12, 12, 16), dtype=float32)\n",
            "output_3\n",
            "Tensor(\"Conv_s_3/re_lu_1/Relu:0\", shape=(?, 8, 8, 16), dtype=float32)\n",
            "output_2\n",
            "Tensor(\"Conv_s_2/re_lu_2/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Printing Output 1\n",
            "Tensor(\"Conv_s_1/re_lu_3/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "outut_1_resized bilinear\n",
            "Tensor(\"feature_merging_branch/ResizeBilinear:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Concatenation of output_2 and output_1_resized\n",
            "Tensor(\"feature_merging_branch/concatenate/concat:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/re_lu_5/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "output_3_resized\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/ResizeBilinear:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_6_1/re_lu_7/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_7_1/re_lu_9/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"dense/Sigmoid:0\", shape=(?, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0715 08:14:11.428897 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "output_4\n",
            "Tensor(\"Conv_s_4/max_pooling2d/MaxPool:0\", shape=(?, 12, 12, 16), dtype=float32)\n",
            "output_3\n",
            "Tensor(\"Conv_s_3/re_lu_1/Relu:0\", shape=(?, 8, 8, 16), dtype=float32)\n",
            "output_2\n",
            "Tensor(\"Conv_s_2/re_lu_2/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Printing Output 1\n",
            "Tensor(\"Conv_s_1/re_lu_3/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "outut_1_resized bilinear\n",
            "Tensor(\"feature_merging_branch/ResizeBilinear:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Concatenation of output_2 and output_1_resized\n",
            "Tensor(\"feature_merging_branch/concatenate/concat:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/re_lu_5/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "output_3_resized\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/ResizeBilinear:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_6_1/re_lu_7/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0715 08:14:14.196934 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"feature_merging_branch/Conv_7_1/re_lu_9/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'global_step': 45, 'iou_eval': 0.5643068, 'loss': 0.063662335},\n",
              " [b'./Graph6/export/Serve/1563178452'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0E2p9UzzO2C",
        "colab_type": "code",
        "outputId": "b8b37d13-18dd-43fd-b931-258d7b454e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "estimator.train(lambda: input_fn(files_pattern,  batch_size , mode=tf.estimator.ModeKeys.TRAIN), steps=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "output_4\n",
            "Tensor(\"Conv_s_4/max_pooling2d/MaxPool:0\", shape=(?, 12, 12, 16), dtype=float32)\n",
            "output_3\n",
            "Tensor(\"Conv_s_3/re_lu_1/Relu:0\", shape=(?, 8, 8, 16), dtype=float32)\n",
            "output_2\n",
            "Tensor(\"Conv_s_2/re_lu_2/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Printing Output 1\n",
            "Tensor(\"Conv_s_1/re_lu_3/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "outut_1_resized bilinear\n",
            "Tensor(\"feature_merging_branch/ResizeBilinear:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Concatenation of output_2 and output_1_resized\n",
            "Tensor(\"feature_merging_branch/concatenate/concat:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/re_lu_5/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "output_3_resized\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/ResizeBilinear:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_6_1/re_lu_7/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_7_1/re_lu_9/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"dense/Sigmoid:0\", shape=(?, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0715 08:14:18.377389 140187324671872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f7fae3c88d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHOVUP2iEw26",
        "colab_type": "code",
        "outputId": "f9ade8fd-d4fc-4c8d-a9dc-9256c3d50e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "estimator.evaluate(lambda: input_fn(files_pattern,  batch_size , mode=tf.estimator.ModeKeys.EVAL), steps=100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "output_4\n",
            "Tensor(\"Conv_s_4/max_pooling2d/MaxPool:0\", shape=(?, 12, 12, 16), dtype=float32)\n",
            "output_3\n",
            "Tensor(\"Conv_s_3/re_lu_1/Relu:0\", shape=(?, 8, 8, 16), dtype=float32)\n",
            "output_2\n",
            "Tensor(\"Conv_s_2/re_lu_2/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Printing Output 1\n",
            "Tensor(\"Conv_s_1/re_lu_3/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "outut_1_resized bilinear\n",
            "Tensor(\"feature_merging_branch/ResizeBilinear:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Concatenation of output_2 and output_1_resized\n",
            "Tensor(\"feature_merging_branch/concatenate/concat:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/re_lu_5/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "output_3_resized\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/ResizeBilinear:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_6_1/re_lu_7/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_7_1/re_lu_9/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"dense/Sigmoid:0\", shape=(?, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'global_step': 90, 'iou_eval': 0.6498231, 'loss': 0.041428823}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_0aCp8F0SJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "l = estimator.predict(lambda: input_fn(test_pattern,  1 , mode=tf.estimator.ModeKeys.PREDICT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpGdLEZC0xyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_bb(preds):\n",
        "  height_image = 28\n",
        "  width_image = 28\n",
        "  bb_box_width = preds[3] * width_image\n",
        "  bb_box_height = preds[4] * height_image\n",
        "  center_x = preds[1] * width_image\n",
        "  center_y = preds[2] * height_image\n",
        "  x_min = (center_x - (bb_box_width / 2))\n",
        "  y_min = (center_y - (bb_box_height / 2))\n",
        "  print(x_min)\n",
        "  print(y_min)\n",
        "  print(bb_box_width)\n",
        "  print(bb_box_height)\n",
        "  \n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.graph._unsafe_unfinalize()\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(['/gdrive/My Drive/indic2019/Test/1.tfrecord'])\n",
        "  dataset = dataset.map(extract_fn)\n",
        "  image, label = dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.graph._unsafe_unfinalize()\n",
        "    img = sess.run(image)\n",
        "  img = img[:,:,0]\n",
        "  print(img.shape)\n",
        "  fig,ax = plt.subplots(1)\n",
        "  ax.imshow(img)\n",
        "  rect = patches.Rectangle((x_min,y_min),bb_box_width,bb_box_height,linewidth=1,edgecolor='r',facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.show()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.graph._unsafe_unfinalize()\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(['/gdrive/My Drive/indic2019/Test/2.tfrecord'])\n",
        "  dataset = dataset.map(extract_fn)\n",
        "  image, label = dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.graph._unsafe_unfinalize()\n",
        "    img = sess.run(image)\n",
        "  img = img[:,:,0]\n",
        "  print(img.shape)\n",
        "  fig,ax = plt.subplots(1)\n",
        "  ax.imshow(img)\n",
        "  rect = patches.Rectangle((x_min,y_min),bb_box_width,bb_box_height,linewidth=1,edgecolor='r',facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxSTyMPbRWRQ",
        "colab_type": "code",
        "outputId": "abf8b337-7434-488c-e1ab-77eb638621c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "count = 0\n",
        "for it in l:\n",
        "  preds = it['coordinates']\n",
        "  if count == 0:\n",
        "    break\n",
        "print(preds)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "output_4\n",
            "Tensor(\"Conv_s_4/max_pooling2d/MaxPool:0\", shape=(?, 12, 12, 16), dtype=float32)\n",
            "output_3\n",
            "Tensor(\"Conv_s_3/re_lu_1/Relu:0\", shape=(?, 8, 8, 16), dtype=float32)\n",
            "output_2\n",
            "Tensor(\"Conv_s_2/re_lu_2/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Printing Output 1\n",
            "Tensor(\"Conv_s_1/re_lu_3/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "outut_1_resized bilinear\n",
            "Tensor(\"feature_merging_branch/ResizeBilinear:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Concatenation of output_2 and output_1_resized\n",
            "Tensor(\"feature_merging_branch/concatenate/concat:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/re_lu_5/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "output_3_resized\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/ResizeBilinear:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_6_1/re_lu_7/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_7_1/re_lu_9/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "[0.85958177 0.47507757 0.5118652  0.7216774  0.6718401 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyop5bqoDhHG",
        "colab_type": "code",
        "outputId": "9c533d1e-9abc-4be6-ac2a-022a02106575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "plot_bb(preds)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.19868803024292\n",
            "4.926464557647705\n",
            "20.20696783065796\n",
            "18.811522006988525\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuQGFMF56N_T",
        "colab_type": "text"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_pp5Aqs7Sxi",
        "colab_type": "code",
        "outputId": "2f1a5289-cd91-4241-bdce-7c321d25a946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "estimator.export_saved_model('saved_model', serving_input_fn)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output_4\n",
            "Tensor(\"Conv_s_4/max_pooling2d/MaxPool:0\", shape=(?, 12, 12, 16), dtype=float32)\n",
            "output_3\n",
            "Tensor(\"Conv_s_3/re_lu_1/Relu:0\", shape=(?, 8, 8, 16), dtype=float32)\n",
            "output_2\n",
            "Tensor(\"Conv_s_2/re_lu_2/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Printing Output 1\n",
            "Tensor(\"Conv_s_1/re_lu_3/Relu:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "outut_1_resized bilinear\n",
            "Tensor(\"feature_merging_branch/ResizeBilinear:0\", shape=(?, 4, 4, 16), dtype=float32)\n",
            "Concatenation of output_2 and output_1_resized\n",
            "Tensor(\"feature_merging_branch/concatenate/concat:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/re_lu_5/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "output_3_resized\n",
            "Tensor(\"feature_merging_branch/Conv_5_1/ResizeBilinear:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_6_1/re_lu_7/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n",
            "Tensor(\"feature_merging_branch/Conv_7_1/re_lu_9/Relu:0\", shape=(?, 2, 2, 16), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'saved_model/1563178505'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTISqgx9exsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To export files from google drive to google ml bucket\n",
        "#!gsutil cp '/gdrive/My Drive/indic2019/Test/*.tfrecord' 'gs://indic2019/indic2019'\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7sgBavrBdHh",
        "colab_type": "code",
        "outputId": "a169f853-aa36-4643-c6ae-e8d300f90b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAA5Z-tOE-zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}